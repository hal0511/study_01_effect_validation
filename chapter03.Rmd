# 傾向スコア(Propensity Score, PS)

## 3.1 傾向スコアの仕組み

### 3.1.1 傾向スコアのアイデア

**傾向スコア**とは各サンプルにおいて介入が行われる確率のこと

傾向スコアを用いた分析は介入が行われた仕組みに着目して、介入グループと非介入グループの性質を近くする操作を行うことになる。これは回帰分析を用いる場合の、介入変数の効果がサンプルの特徴によって異なる場合とそうでない場合、推定される効果の性質が異なってしまう問題を回避することができる。

回帰分析の仮定CIA (Conditional Independence Assumption) とはモデルに使われている共変量 $X_i$ の値が同じ値を持つサンプルの中で、介入 $Z$ が $Y^{(0)}$ とは独立に振り分けられていること\
傾向スコアは、大まかには、介入が割り振られる確率 $P(X_i)$ が*同一になるようなサンプルの中では*介入 $Z$ が $Y^{(0)}$ とは独立に割りるられているという仮定\
なので、違いは「今日変量で条件付けするのではなく、共変量から算出された介入の割りふり確率で条件付けされたサンプルの中で介入の割りふりが独立である」と考える部分。CIAと比べゆるくなっている

共変量の値がどうであれ算出される傾向スコアの値が同じであれば $Y^{(0)}$ とは独立に決定されていると考える

$$
\{Y^{(1)}, Y^{(0)}\} \perp Z|P(X)
$$

この $Z$ を割り振る確率 $P(X)$ を傾向スコアと呼ぶ

### 3.1.2 傾向スコアの推定

傾向スコアを直接観測できる状況はほとんどないけど、割り当ての結果である $Z$ は観測されている\
ってことで、何らかのモデルを用いて手持ちデータから傾向スコアを推定することはできる。よく使われるのはロジスティック回帰らしいけど、GBDTやランダムフォレストとかでもok。

以下、ロジスティック回帰式

$$
\begin{align}
Z_i &= \sigma(\beta X_i+u_i) \\
\sigma(x) &= \frac{x}{1 + e^{-x}} \\
\hat{P}(X_i) &= \hat{Z}_i = \sigma(\hat{\beta}X_i)
\end{align}
$$

$u$ は誤差項, $\beta$ は推定されるパラメータ, $\sigma$ はシグモイド関数

```{R}
# 準備（ライブラリとデータのロード）
library(pacman)
pacman::p_load(readr, stats)

biased_data = readr::read_csv(file = './biased_data.cvs')
```

```{R}
# 傾向スコアの算出(モデル作り)
ps_model <- stats::glm(data = biased_data, 
                       formula = treatment ~ recency + history + channel, 
                       family = binomial)
print(ps_model) # これを見る必要はないけど、一応出す
```

glm(Generalized Linear Models)は名前のまま一般線形化モデルを使うためのパッケージ\
familyでモデルを選べる(binomial, gaussian, Gamma, inverse.gaussian, poisson)

予測値として得られる値が重要であり、パラメータ(式の $\beta$ の部分)は分析に使わないし興味もない。\
興味がないってのは、パラメータの値が直感に即している/反しているなど解釈もどうでもいいし、効果の分析においてはその質の保証にならない。

## 3.2 傾向スコアを利用した効果の推定

得られた傾向スコアを利用してサンプル同士をマッチングさせる**傾向スコアマッチング**と, 傾向スコアをサンプルの重みとして利用する**逆確率重み付き推定(Inverse Probability Weight; IPW)** が紹介されている

### 3.2.1 傾向スコアマッチング

介入が行われているグループからサンプルを取り出し、そのサンプルと近い値の傾向スコアを持つサンプルを介入が行われていないグループからマッチングしてペアにする。そして、ペアの中で目的変数の差を算出し、その平均を取ったものを効果の推定値とする

傾向スコアが同じ値を持つサンプルの中で介入変数 $Z$ は $Y^{(0)}$ とは無関係に決定されていると仮定しているので、\
この中でグループ間の比較をしてもセレクションバイアスの影響を受けないことが理由

$$
\hat{\tau}_{match} = E\{E[Y|P(X), Z=1] - E[Y|P(X), Z=0] |1 \}
$$

これがマッチングが母集団において推定している効果, ATT(Average Treatment effect on Treated, 介入効果を受けたサンプルにおける介入効果の期待値)。\
なので、平均的な効果を推定した値とは結果が異なる可能性がある。(介入群と非介入群で効果量が違う時は顕著)

Rでやる場合には **MatchIt** パッケージを使える

```{R}
pacman::p_load(MatchIt, broom, tidyr)

# 傾向スコアを利用したマッチング
m_near <- MatchIt::matchit(formula = treatment ~ recency + history + channel, 
                           data = biased_data, 
                           method = 'nearest', 
                           replace = TRUE)

# マッチング後のデータを作成
matched_data <- MatchIt::match.data(m_near)

# マッチング後のデータで効果を推定
PSM_result <- matched_data %>%
  lm(spend ~ treatment, data = .) %>%
  broom::tidy()
```

matchitでATTの推定がされる. methodでマッチング方法を選べる(nearest, optimal, full, quick, genetic, cem, exact, cardinality, subclass). ここでは最近傍マッチング(nearest neighbor matching)でやっている

```{R}
print(m_near)
```

これを使ってmatch.dataするとマッチングが行われた後のデータフレームを手に入れ、このデータで平均の差を求めると効果を推定できる。\
平均の差を求めるのは、介入変数のみを含む回帰変数を行うことで、回帰分析の時と同様に結果解釈できる

```{R}
print(PSM_result)
```

estimateが0.85ってことでメールによる介入で平均的に\$0.85程度の売り上げ増加が起きていると推定できる

### 3.2.2 逆確率重み付き推定

傾向スコアの別の利用方法、サンプルの重みとして利用し、与えられたデータ全体での介入を受けた場合の結果の期待値と、介入を受けなかった場合の結果の期待値を推定する。最後に、この２つの期待値の差を取ることで効果を推定する。

重み付けをせずに単純に平均値をとってしまうと、それは $E[Y^{(1)}|Z=1]$と, $E[Y^{(0)}|Z=0]$ の推定値となってしまうので、この差を取るとセレクションバイアスの影響を受けてしまう。

$$
\begin{align}
\overline{Y}^{(1)} &= \sum_{i=1}^{N} \frac{Z_iY_i}{\hat{P}(X_i)} / \sum_{i=1}^{N}\frac{Z_i}{\hat{P}(X_i)} \\
\overline{Y}^{(0)} &= \sum_{i=1}^{N} \frac{(1-Z_i)Y_i}{1-\hat{P}(X_i)} / \sum_{i=1}^{N}\frac{1-Z_i}{1-\hat{P}(X_i)} \\
\hat{\tau}_{IPW} &= \overline{Y}^{(1)} - \overline{Y}^{(0)} 
\end{align}
$$

**WeightIt** パッケージを使う

```{R}
library(WeightIt)

# 重みの推定
weighting <- WeightIt::weightit(formula = treatment ~ recency + history + channel,
                                data = biased_data,
                                method = 'ps',
                                estimand = 'ATE')

# 重み付きデータでの効果の推定
IPW_result <- lm(data = biased_data,
                 formula = spend ~ treatment,
                 weights = weighting$weights) %>%
  broom::tidy()
```

```{R}
print(IPW_result)
```

estimateについて, Interceptが $E[Y^{(0)}]$ の推定値で, treatmentが $E[Y^{(1)}] - E[Y^{(0)}]$ の推定値となる\
ってことで、こっちは\$0.86となり、傾向スコアマッチングの結果とほぼ同じとなった。

### 3.2.3 より良い傾向スコアとは

傾向スコアもどんなに頑張ってもセレクションバイアスを消し去ってくれるパーフェクトな道具ではない\
なので、より良いところを目指すしかなく、その「より良い」とは「共変量のバランスが取れている」こととなる

共変量のバランスがとれているかの確認は、共変量の平均値が近い値であるかを確認する\
マッチングの場合はマッチングの結果得られたデータで比較を行い、IPWの場合は重みづけを行なったデータの中で比較する

**cobalt**を使うと可視化が簡単にできる\
横軸にそれぞれの共変量の標準化平均差、縦軸に共変量の種類をとっている\
（標準化平均差とは平均の差をその標準偏差で割った値）\
横の散らばりを見ると介入を受けたグループと非介入グループで各変数の平均にどの程度の差があるかわかる\
調整前(Unadjusted)がマッチングや重みで調整される前の共変量なので、調整後に介入/非介入の差がないことが望ましい。閾値にしている0.1より小さいと十分バランスがとれていると考えられる

```{R}
library(cobalt)

# マッチングしたデータでの共変量のバランス
cobalt::love.plot(m_near, thresholds = 0.1)
```

```{R}
cobalt::love.plot(weighting, thresholds = 0.1)
```

### 3.2.4 傾向スコアと回帰分析の比較

回帰分析メリット

-   めちゃお手軽、手っ取り早い

-   モデリングが正しくできていれば標準誤差が小さくなる

-   OVBのようにバイアスについて直感的で分かりやすい説明が可能

回帰分析デメリット

-   目的変数Yと共変量Xのモデリングをちゃんとやらないといけない

傾向スコアメリット

-   Yに対するモデリングを行わなくてok

-   介入変数Zの決定方法に関する調査やヒアリングだけでいいので実用上のメリット

-   Yについての情報がないけど、Zについての情報があるならこっち

傾向スコアのデメリット

-   計算に時間がかかるので大量のレコード分析には向かない（最近のPCなら問題ないかも？）

### 3.2.5 マッチングとIPWの差

今回使ったデータではいい感じに近い値になったけど、多くの場合には両者の結果は一致しないらしい\
というか、回帰の結果とすら一致しない場合がある\
これは、そもそもそれぞれの分析で推定しようとしているものが違うことが理由 マッチングでATTの推定を行う場合はZ=1となるそれぞれのサンプルに対して、それに似ているZ=0のサンプルが選ばれてマッチングされる。この時、Z=0の選ばれなかったデータは捨てられることになる。なので結果は、元データでZ=1になるポテンシャルがあったデータに絞り込まれたサンプルでの平均的な効果ということになる。

IPWは重みづけなので、得られたデータ全てを使用して期待値を推定する。なので、仮にRCTしていたらどんな結果になっていたかを推定していることに等しい。(つまりATEの推定)

## 3.3 機械学習を利用したメールマーケティング施策の効果検証

介入対象の選定方法を自動的に決定している場合は、入手できるログデータに介入の割りふり確率（＝傾向スコア）が残されている場合がある。\
もし、傾向スコアのログデータがなくても、介入を決定する仕組みの正確な情報が残されていることは多い。\
これらの場合は傾向スコアを用いた分析がやりやすくなる\
そんなことを想定したシミュレーション

### 3.3.1 データの作成

```{R}
set.seed(1)

library(pacman)  
pacman::p_load(
  tidyverse,
  readr,
  broom,
  stats
  )

# load data
email_data <- readr::read_csv("http://www.minethatdata.com/Kevin_Hillstrom_MineThatData_E-MailAnalytics_DataMiningChallenge_2008.03.20.csv")

male_df <- email_data %>%
  dplyr::filter(segment != 'Womens E-Mail') %>%
  dplyr::mutate(
    treatment = if_else(segment == 'Mens E-Mail', 1, 0)
  )

# 男性データをランダムに２つに分割
# sample(x, size)なので行数を行数の半分だけ抽出
train_flg <- sample(NROW(male_df), NROW(male_df)/2, replace = FALSE)

# train_flgをつけたデータのうち, メールが配信されていないデータを抽出
male_df_train <- male_df[train_flg, ] %>%
  dplyr::filter(treatment == 0)

# train_flgに含まれない行を抽出
male_df_test <- male_df[-train_flg, ]

# 売上が発生する確率を予測するモデルの作成
prediction_model <- stats::glm(data = male_df_train, 
                               formula = conversion ~ recency + history_segment + channel + zip_code, 
                               family = binomial)
```

prediction_modelはメールが配信されていないデータを学習させているため、メールが配信されていない場合に売上が発生する確率を予測できる。\
予測値のパーセントランクを算出し、サンプルの予測値の大きさが下から何%に当たるのかだす\
この値を介入が起きる確率として扱い、介入を割り振る。介入の割り振り方はパーセントランク値と二項分布に従った乱数によって決定させる

```{R}
# 作ったモデルを用いてmale_df_testに対して配信確率をつける
pred_cv <- stats::predict(prediction_model, 
                          newdata = male_df_test, 
                          type = 'response')

# 配信確率のパーセントランク値を作る
pred_cv_rank <- dplyr::percent_rank(pred_cv)

# 配信確率をもとにメールの配信を決定させる
mail_assign <- sapply(pred_cv_rank, stats::rbinom, n = 1, size = 1)

# 配信
ml_male_df <- male_df_test %>%
  mutate(
    mail_assign = mail_assign,
    ps = pred_cv_rank
  ) %>%
  dplyr::filter(
    (treatment == 1 & mail_assign == 1) |
      (treatment ==0 & mail_assign == 0)
  )
```

これでセレクションバイアスの入ったサンプルデータの作成終わり\
メール配信されていない時期のデータに基づいて売り上げを発生させそうなユーザーを予測し、そのようなユーザーに重点的にメールを配信した内容になっている

### 3.3.2 RCTと平均を比較

ちゃんとバイアスがかかっているか確認するために、ランダムにメールを配信した場合に得られる分析結果を見てみる

```{R}
# RCTの方
rct_male_lm <- lm(data = male_df_test, 
                  formula = spend ~ treatment) %>%
  broom::tidy()

print(rct_male_lm)
```

```{R}
# 操作した方
ml_male_lm <- lm(data = ml_male_df, 
                 formula = spend ~ treatment) %>%
  broom::tidy()

print(ml_male_lm)
```

treatmentのestimateを見ると0.76と1.13で結構上振れている結果になっているので、セレクションバイアスによって効果が過剰評価されていることが確認できる

### 3.3.3 傾向スコアを用いた分析

パーセントランクが介入を決定させていた（＝傾向スコア）なので、分析でもこれを使ってマッチングを行う

```{R}
# すでにある傾向スコアを利用してマッチングを行うためのライブラリ
library(Matching)

# Y(目的変数), Tr(介入変数), X(傾向スコアのデータ), estimand(Estimateで何を表すか)
PSM_result <- Matching::Match(Y = ml_male_df$spend,
                              Tr = ml_male_df$treatment, 
                              X = ml_male_df$ps,
                              estimand = 'ATT')
summary(PSM_result)
```

ATTは1.19であるがp_valueが0.1と大きいのでちょっと気をつけたほうがいい、効果があるとは言えない。

```{R}
# IPWでやってみる
W_out <- WeightIt::weightit(formula = treatment ~ recency + history_segment + channel + zip_code,
                            data = ml_male_df,
                            ps = ml_male_df$ps,
                            estimand = 'ATE')

# 重みづけしたデーアでの共変量のバランスを確認
cobalt::love.plot(W_out, thresholds = 0.1)
```

すんごくバランスが良くなっちる

```{R}
IPW_result <- ml_male_df %>%
  lm(data = .,
     formula = spend ~ treatment,
     weights = W_out$weights) %>%
  broom::tidy()

print(IPW_result)
```

0.88となった。p_value \< 0.01なので、こっちの結果は参考にしても良さそう\
RCTの結果とも近いのできちんとセレクションバイアスを軽減できていることが見てとれる

注意点として、メール配信の意思決定にランダム性がないケースは往々にして存在する。\
予測値が一定以上の場合にはメールを送信するような状況とか。ここで紹介されていた方法では傾向スコアは1or0の値としていたので、おんなじ方法を取ることはできない。その時は**回帰不連続デザイン(Regression Discontinuity Design; RDD)**を利用する
