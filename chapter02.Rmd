# chapter02 介入効果を図るための回帰分析

## 2.1 回帰分析の導入

### 2.1.2 効果分析のための回帰分析

介入効果は施策の有無における結果の期待値の差分 $\tau = E[Y^{(1)}] - E[Y^{0}]$で表される.

この章で登場する３つの変数

-   被説明変数( Y: dependent variable)

    -   効果を確認したい変数. メールの例であれば購買量

-   介入変数(Z: treatment variable)

    -   施策の有無を表す変数. メールの例では配信するか否か

-   共変量(X: control variable)

    -   セレクションバイアスを発生させていると分析者が想定する変数

    -   介入や施策の有無で傾向が異なっていると想定される変数. メールの例なら去年の購買量など

$Y = E[Y|X, Z] + u = \beta_0 + \beta_1X+\beta_2Z + u$ の関係が成り立つ.

$u$ は誤差項で $u_i = Y_i - (\beta_0 + \beta_1X_i + \beta_2Z_i)$ で表される.

### 2.1.3 回帰分析による効果の推定

年齢が上がるにつれて１年分の経験が収入に対して持つ影響が少なくなると仮定したとき\
その関係は二次関数で表されることが知られているため, 本来の $X$ に加えて $X^2$ を加える必要がある（らしい）\
ので，それを組み込んだ回帰モデルとする

介入あり: $E[Y|X,Z = 1] = \beta_0 + \beta_1X+\beta_2X^2+\beta_31$\
介入なし: $E[Y|X,Z = 0] = \beta_0 + \beta_1X+\beta_2X^2+\beta_30$

介入効果は２つの差のため $\beta_3$ だけとなる

### 2.1.5 Rによるメールマーケティングデータの分析（回帰編）

$\text{Spend}_i = \beta_0 + \beta_{treatment}\text{treatment}_i + \beta_{history}\text{history}_i$

変数の意味は次のとおり. Spend: 購入額, treatment: 介入変数, history: 過去の購入額

これをデータフレームに対してRで書くと $send \sim treatment + history$となる

```{r, eval =TRUE}
library(pacman)  
pacman::p_load(
  tidyverse,
  readr,
  broom
  )

biased_data <- readr::read_csv('./biased_data.cvs')
male_df <- readr::read_csv('./sample_marketing_data.csv') %>%
  dplyr::filter(segment != 'Womens E-Mail') %>%
  dplyr::mutate(
    treatment = if_else(segment == 'Mens E-Mail', 1, 0)
  )
```

回帰分析の実行

```{r}
biased_reg <- lm(data = biased_data,
                 formula = spend ~ treatment + history)
summary(biased_reg)
```

注目するのは Coefficients の部分\
推定されたパラメータの値 (Estimate) とその標準偏差 (Std. Error) やt検定の結果 (t value, Pr \> \|t\|) がある

この結果では以下のように出ている

$\beta_0$ (Intercept) = 0.3242, $\beta_{treatment}$ (treatment) = 0.9026, $\beta_{history}$ (history) = 0.001

介入効果 (treatment) は Pr(t) = 2.25e-07 ととても小さいので有意であり帰無仮説「メールの送信に効果はない」を棄却できる．また Estimate が0.90であることから，メールを送信することで平均0.9ほど増加すると解釈可能

効果検証での回帰分析では Coefficients 以外の情報を気にしないため，この本でも今後は Coefficients のみ表示されるようにする\
`broom::tidy()` は `lm()` で出力される結果をデータフレームに変換してくれる

```{r}
# 今後は冒頭にpacman::p_load で一緒に入れとく
library(broom)
# 結果を tidy() に渡せばok
biased_reg_coef <- broom::tidy(biased_reg)
biased_reg_coef
```

### 2.1.6 効果検証のための回帰分析で行わないこと

$\beta_{treatment}$ 以外の推定値も得られるけども，効果検証のための回帰分析では $\beta_{treatment}$ 以外には興味ない\
そのため，他の推定値が本当の効果を表すようにする努力もしない（変数は互いに独立でなければいけないなど）\
有意差検定についても同様であり， $\beta_{treatment}$ 以外の検定については一切解釈を行わない．どうでもいい\
別の章でも触れるが $\beta_{treatment}$ に対して交絡が大きい変数を選ぶほどバイアス除去に役立つ点も予測に用いる回帰式の作り方とはコンセプトから異なる．

回帰分析で得られた式は各変数が正しく推定されているならば, y( $\text{Spend}$ ) の予測に使うこともできるけど\
前述の通り，ここで作る回帰式は効果検証以外の目的を持たない．（予測結果の担保をしない）

## 2.2 回帰分析におけるバイアス

### 2.2.1 共変量の追加による効果

セレクションバイアスが小さくなるような推定を行うためには共変量の選択が重要\
まずは，共変量とセレクションバイアスの関係性について理解する

```{r}
# ---- library ----
# 同じセッションであれば再度ロードする必要はないけど，何となく書きたい
library(pacman)
pacman::p_load(
  tidyverse,
  readr,
  broom
)

# Single regression on RCT data
rct_reg <- lm(data = male_df, formula = spend ~ treatment)
rct_reg_coef <- broom::tidy(rct_reg)

# Single regression on Biased data
biased_reg <- lm(data = biased_data, formula = spend ~ treatment)
biased_reg_coef <- broom::tidy(biased_reg)

print(rct_reg_coef)
print(biased_reg_coef)
```

結果はこちら⇩

| RCT data  |  Estimate | std.error | statistic |      p.value |
|:---------:|----------:|----------:|----------:|-------------:|
| treatment | 0.7698272 | 0.1452479 |  5.300090 | 1.163201e-07 |

| Biased data |  Estimate | std.error | statistic |      p.value |
|:-----------:|----------:|----------:|----------:|-------------:|
|  treatment  | 0.9794465 |  0.172717 |  5.670817 | 1.433467e-08 |

Chapter01のsummary_by_segmentで出した試作有無での平均値の差は0.767 (= 介入効果）であり，RCTの結果のEstimate(0.7698) とかなり近いことが見てとれる．一方バイアスを作ったデータでは0.979と過剰に評価（推定）されていることが見てとれる.

次にバイアス軽減を目的として共変量を加えた以下のモデルを作る\
共変量はバイアスを作るときに使った recency, history, channelの３つ

$$
\begin{align}
Spend_i &= \beta_0 + \beta_{treatment}\text{treatment}_i \\
&+ \beta_{recency}\text{recency}_i + \beta_{channel}\text{channel}_i + \beta_{history}\text{history}_i + u_i
\end{align}
$$

```{r}
nonrct_mreg <- lm(data = biased_data,
                  formula = spend ~ treatment + recency + channel + history)
nonrct_mreg_coef <- broom::tidy(nonrct_mreg)

print(nonrct_mreg_coef)
```

treatmentのEstimateを見ると0.847で0.767に近づいたことから，共変量を組み込むことでバイアスの低減に役に立つことがわかった

### 2.2.2 脱落変数バイアス(OVB)

脱落変数とは，本来必要であるがモデルから抜け落ちている変数のこと\
これが抜け落ちていることによるバイアスのことを脱落変数バイアス(Omitted Variable Bias)と呼ぶ\
(参考：[重回帰分析 \| 拓殖大学](http://www.ner.takushoku-u.ac.jp/masano/class_material/waseda/keiryo/R25_reg8_OBV.html))

以下のモデルA, Bを考える. 違いは 共変量 $X_{omit, i}$ が追加されているかどうか\
つまり, B の方は共変量によってセレクションバイアスが低減されているモデルとなる\
この共変量が **脱落変数** のこと

$$
\begin{align}
Y_i &= \alpha_0 + \alpha_1Z_i + u_i \ &\text{(model A)} \\
Y_i &= \beta_0 + \beta_1Z_i + \beta_2X_{omit, i} + e_i \ &\text{(model B)}
\end{align}
$$

$Z_i$ は介入変数であり, $\alpha_i,\  \beta_i$ はそれぞれのパラメータとなる\
ここでの興味は介入変数の効果が２つのモデル間でどのような差があり，どのように決定されているかとなる\
2つの違いは省略されている共変量にあり，Bでの共変量と誤差項はAの $u_i$ に含まれていることになるので\
$u_i = \beta_2X_{omit, i} + e_i$ と表すことができる

だいぶ端折って, $X_{omit, i}$ を無視したA の介入効果を示すパラメータ $\alpha_1$ は次のようになることが知られている

$$
\alpha_1 = \beta_1 + \gamma_1\beta_2 
$$

$\beta_1$ はBにて推定される効果を示しており，セレクションバイアスがうまく取り除かれた結果となる\
つまり，$\alpha_1$ は本来正しく推定されるはずだった $\beta_1$ に何かしらの値をとる $\gamma_1\beta_2$ を加えたものとの解釈になる(OVB)

この比較は回帰分析の基本的な以下の仕組みを示している

1.  必要な共変量がモデルに含まれない場合に推定される効果にはOVBが含まれる
2.  必要な共変量をモデルに加えることでOVBは取り除くことができる

$\beta_2$ はモデルBの式を見るように $X_{omit,i}$ と $Y_i$ の相関に当たるものであり\
$\gamma_1$ は $X_{omit, i} = \gamma_1Z_i+\epsilon_i$ と表すように$Z_i$ を回帰させた時の回帰係数，とすると$Z_i$ と $X_{omit, i}$ の相関と考えられる\
本当は $X_{omit}$ が $Y$ に影響を与えているのに $X_{omit}$ と $Z$ の相関を通して $Z$ の効果として見える

本当は部下の功績が大きいのに，報告した上司の手柄になるみたい．\
なので，効果分析において本当に興味のあるパラメータ以外の有意差検定の数字を見て共変量を取捨選択することは害悪にすらなり得る

### 2.2.3 RによるOVBの確認

$$
\begin{align}
\text{Spend}_i &= \alpha_0 + \alpha_1\text{treatment}_i + \alpha_2\text{recency}_i + \alpha_3\text{channel}_i + e_i &\text{(model A)}\\
\text{Spend}_i &= \beta_0 + \beta_1\text{treatment}_i + \beta_2\text{recency}_i + \beta_3\text{channel}_i + \beta_4\text{history}_i + u_i &\text{(model B)}
\end{align}
$$

AとBは共変量 history が含まれるか否かとなる．history は過去の購入額を表す変数なので，売上に対して相関を持つ．また，バイアス加工したデータにおいて，historyが300以上の場合には介入が起こりやすくなるようにし，バイアス加工したデータにおいては historyを外すことで脱落バイアスが発生するように作っている.

OVBは $\alpha_1 - \beta_1 = \gamma_1 \beta_1$ なので,\
$\gamma_1$ はモデルAで脱落している history に対してモデルA に含まれている変数で行う回帰式で推定された値となる

$$
\text{history}_i = \gamma_0 + \gamma_1\text{treatment}_i + \gamma_2\text{recency}_i + \gamma_3\text{channel}_i + \epsilon_i \ \text{(model C)}
$$

では，モデルを作っていく

```{r}
# broom は複数の回帰式をまとめて処理できるの
# モデル式のベクトルを用意して
formula_vec <- c(spend ~ treatment + recency + channel,
                 spend ~ treatment + recency + channel + history,
                 history ~ treatment + channel + recency)

# formla に名前をつける, names は要素に名前をつけることができる．辞書みたい
# LETTERSはA~Zが入っているベクトルオブジェクト, [1:3]でA, B, Cが取り出せる
# pasteはconcatみたいなやつ．区切りを指定できる
names(formula_vec) <- paste('reg', LETTERS[1:3], sep = '_')

# enframeでtibbleに変換, value = formulaで渡せるんだ，リストで渡さなくていいのか便利
models <- formula_vec %>% 
  tibble::enframe(name = 'model_index', value = 'formula')

# mapを使って各回帰式を実行
# mapは.xでカラム指定, .f で指定したカラムに与えた関数を実行, 引数のdataでlmに使うデータを指定
# そのモデル結果に対してmapでtidy()を実行
df_models <- models %>%
  mutate(
    model = map(.x = formula, .f = lm, data = biased_data)
  ) %>%
  mutate(
    lm_result = map(.x = model, .f = tidy)
  )

# df_modelsはtibbleにtibbleが入っている状態なので，そのままだと結果が見れない
# なので整形する
df_results <- df_models %>%
  mutate(
    formula = as.character(formula)
  ) %>%
  select(
    formula, model_index, lm_result
  ) %>%
  unnest(
    cols = c(lm_result)
  )

# df_resultsはunnestされた状態なので縦持ち．見えるけど，かったるい
# df_results
```

欲しいのは脱落バイアスの２つの表現方法（右辺と左辺）である $\alpha_1 - \beta_1$ と $\gamma_1\beta_4$\
$\alpha_1, \beta_1, \gamma_1$ は treatmentのパラメータなので `filter(term == treatment)`で取り出せる\
$\beta_4$ はモデルBのhistoryのパラメータなので `filter(model_index == 'reg_B' and term == 'history')`

```{r}
# treatmentのベクトルを取り出す
treatment_coef <- df_results %>%
  dplyr::filter(
    term == 'treatment'
  ) %>%
  pull(
    estimate
  )

# historyを取り出す
history_coef <- df_results %>%
  dplyr::filter(
    model_index == 'reg_B',
    term == 'history'
  ) %>%
  pull(
    estimate
  )

# a1 - b1
coef_gap <- treatment_coef[1] - treatment_coef[2]
# beta2 * gamma1
OVB <- history_coef * treatment_coef[3]

coef_gap # 0.02805398
OVB # 0.02805398
# ちゃんと一致した
```

$\alpha_1 - \beta_1 = \gamma_1 \beta_1$ が綺麗に出たので，共変量を追加することでOVBが消失することであることに由来するとわかる

### 2.2.4 OVBが与えてくれる情報

OVBの式は共変量が不十分なモデルの持つ構造, つまり「脱落変数 $X_{omit}$ と介入変数 $Z$ の関係」と「 $X_{omit}$ と目的変数 $Y$ の関係」を掛け合わせたのがバイアスとなることを表している.\
そして，このような $Z$ と $Y$ に関係のある変数のことを **交絡因子** と呼ぶ.

目的変数との相関が0ではない変数はYを**予測するとき**に回帰モデルにおいて含まれるべき存在とされているが，\
その変数と $Z$ の相関が0であればOVBの値が０となるため, **効果測定のため**の回帰モデルに加える意味はない

バイアスを発生させるような介在変数 $X_{omit}$ がデータとして手に入らない場合にも，その変数と $Y$, $Z$ との関係が正か負になるかを考えることで，今得られている効果の推定結果が過小に評価されているのか，過大に評価されているのかを想定できる

### 2.2.5 Conditional Independence Assumption (CIA)

モデルに含まれていない変数によるOVBが全て0になるような状態では，モデルに含めた共変量で条件付けしたときに，介入変数が $Y^{(1)}$ や $Y^{(0)}$ とは独立している状態になる．これを **Conditional Independence Assumption (CIA)** と呼ぶ．

$$
\{Y_i^{(1)}, Y_i^{(0)}\} \perp Z_i | X_i
$$

回帰分析で推定した効果の値が本当に正しいのか考える場合, CIAが満たされているか否かを考える必要がある

### 2.2.6 変数の選び方とモデルの評価

手順は大体こんな感じ

1.  介入の割り当てがどのようにして決定されているのかを考える
2.  1にて想定される決定方法を表現できるような共変量を選択する
3.  選択した共変量と *Y* との関係性を考慮してそれぞれの関数を決める

この時, 作ったモデルの共変量がCIAを満たしていると考える必要があるが, 2つの問題がある

1.  バイアスを評価できないという問題\
    OVBはモデル間のバイアスの変化を示すものであり，バイアスの値を評価するものではない\
    なので，分析者はセレクションバイアスがどのような理由で発生しているか考え, どの組み合わせでモデルに含めるなどのコントロールをするしかない.
2.  必要な共変量がデータにはないという問題\
    手元にあるデータだけではバイアスが十分に減らせない可能性はある\
    また，セレクションバイアスを発生させている要因を知っていても，そのデータを定義できない・手に入れられないケースは実務上は沢山ある

より応用的な手法を取ることで，これらの問題に対応することも可能．

-   操作変数法

-   固定効果モデル

**Sensitivity Analysis**は手持ちのデーアには含まれない変数がセレクションバイアスが発生させているかどうかを評価する方法．これは重要だと分析者が認識している共変量以外の共変量をモデルから抜くことで，効果の推定値が大きく変動しないかを確認する分析手法となる\
変動が小さければ回帰分析の結果が他の変数による影響を受けにくいことを示しており，データセットに含まれていないような変数を含めたとしても大きく変化しないことを示唆する

### 2.2.7 Post treatment bias

セレクションバイアスが減る可能性があるからといってOVBの値が０でない変数をなんでもモデルに入れていいわけではない. 介入の影響を受けるような変数をモデルに含めた場合, 回帰分析の結果が歪んでしまうことがある

メールマーケティングの例をとってみる\
メールマーケティングにおいてはサイト訪問を示す $visit_i$ が介入の影響を受ける変数として挙げられる\
ユーザーはサイトに訪問しなければ買い物ができないため, サイト訪問 $X$ と購入 $Y$ には相関があることはわかる\
また，メールの配信はサイトの訪問を喚起させるため $Z$ とも相関がある

```{r}
# 入れてはいけない変数(visit)と介入変数(treatment)との相関
cor_visit_treatment <- lm(
  data = biased_data,
  formula = treatment ~ visit + channel + recency + history
  ) %>%
  broom::tidy()

cor_visit_treatment
```

介入変数との相関，共変量を取り除いた状態で estimate が 0.14, p_value = 2.30e-79 と統計的に有意であるの\
なんでモデルに入れてもいいかなーと．

サイト訪問を効果検証の回帰モデルに入れてみる

```{r}
bad_control_reg <- lm(
  data = biased_data,
  formula = spend ~ treatment + channel + recency + history + visit
  ) %>%
  broom::tidy()

bad_control_reg
```

treatmentはvisitを入れる前には0.847あったのに，0.294まで効果が大きく低下してしまった...あーあ.

これはメールの配信が元々購買傾向が弱いユーザーのサイト訪問を増やしていることにある\
サイト訪問したユーザーの内訳を考えると\
メール配信されたグループは(A)配信がなくてもサイトへ来訪するような購買傾向の強いユーザーと(B)メールがあるからサイトへ訪問するような購買傾向の弱いユーザーで構成され\
メールが配信されなかったグループは(A)元々の購買傾向が強いユーザーのみサイトへ訪問していることになる\
なので，サイトへ訪問したユーザーを比較するとメール配信がされなかったグループの方が売上の平均が高い結果になる（メール配信の効果が薄まっているとも捉えることができる）

このように介入を受けたことによって変化した変数によって引き起こされるバイアスが **Post Treatment Bias**

これを避けるためには介入よりも後のタイミングで値が決まるような変数は分析から除外する必要がある\
ただこれは分析者のドメイン知識に精度が左右される

また，Post Treatment Biasは変数選択に限った問題ではない\
例えばどのユーザーが実際に広告を目にしたか特定出来ないが，広告クリックによってサービス流入が起きたユーザーのみはログを取得できる場合(GA4のutm系など).\
このような場合にサイトアクセスを誘発する広告施策を実施すると，広告配信グループには購買意欲や利用意向の少ないユーザーが多くなり，配信していないグループには元々購買意欲が強いユーザーといった状態になる

やってしまうと，介入グループの方がCVが小さい結果になってしまう.\
ランダムに選んだとしてもこれは発生する．

自社サービス内の施策を評価する場合はすべてのユーザーのデータが得られることが多いのでok\
ただ，外からユーザーを誘引するような施策を評価する場合には大きな問題となる\
ユーザー全体のデータを用意する重要さよ（配信リストがわかっていればok）

## 
